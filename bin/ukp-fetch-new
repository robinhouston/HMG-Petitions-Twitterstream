#!/usr/bin/python -u
# -*- encoding: utf-8 -*-

# Fetch new petitions

import logging
import os
import sys
import time

home = os.path.normpath(os.path.join(os.path.dirname(__file__), os.path.pardir))
sys.path = [os.path.join(home, "lib")] + sys.path + [home]

import redis

import ukpetitions.scraper

# How many consecutive petitions do we need to see that we have seen
# already, to conclude there are no more for us to find.
MAX_CONSECUTIVE = 20

# The minimum length of time to sleep between fetches
MIN_SLEEP_SECS = 30

# The maximum length of time to sleep between fetches
MAX_SLEEP_SECS = 3600

class Fetcher(object):
    def __init__(self, r):
        self.r = r
        self.scraper = ukpetitions.scraper.PetitionScraper()
    
    def get_new_petitions(self):
        r = self.r
        
        new_links = []
        consecutive_already = 0
        for link, petition in self.scraper.fetch_petitions():
            logging.info("Looking at %s", link)
            if r.exists(link):
                logging.info("%s already exists", link)
                consecutive_already += 1
                if consecutive_already == MAX_CONSECUTIVE:
                    logging.info("Found %d consecutive already-seen entries; stopping.", consecutive_already)
                    break
                else:
                    continue
            
            consecutive_already = 0
            new_links.append(link)
            
            logging.info("Loading %s (%s)", link, petition["title"])
            for k, v in petition.items():
                r.hset(link, k, v)
            
            r.lpush("oldest-first", link)
        
        new_links.reverse() # Order them oldest-first
        return new_links
    
    def queue_new_petitions(self):
        new_links = self.get_new_petitions()
        for link in new_links:
            self.r.rpush("new-and-untweeted", link)
        return bool(new_links)
    
    def loop(self):
        sleep_secs = MIN_SLEEP_SECS
        while True:
            if self.queue_new_petitions():
                sleep_secs = MIN_SLEEP_SECS
            else:
                sleep_secs = min(sleep_secs * 2, MAX_SLEEP_SECS)
            logging.info("Sleeping for %d seconds", sleep_secs)
            time.sleep(sleep_secs)

def main():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
    Fetcher(redis.Redis()).loop()

if __name__ == "__main__":
    main()
